{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEq40taKKDjG"
   },
   "outputs": [],
   "source": [
    "import cv2, numpy as np, pandas as pd, os, shutil, pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvfGKn1zQHT_"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, mean_squared_error as mse, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_biinROS1qZq"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "8dxkSX65QHUM",
    "outputId": "2b057758-c819-455e-92c8-a6204c5b8b7e"
   },
   "outputs": [],
   "source": [
    "# !pip3 install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "We9Nol9XKDjo",
    "outputId": "632d74e0-e61c-41df-d14d-7e1834462151"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "try: from keras.callbacks.callbacks import ModelCheckpoint\n",
    "except:  from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, LeakyReLU, BatchNormalization, Conv1D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "mIzfydx1KGzn",
    "outputId": "46f117fd-52a3-46b3-97c2-cae3ad7a020d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnning on LOCAL SYSTEM\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # to run on colab\n",
    "    from google.colab import drive\n",
    "    def mount_drive():\n",
    "        drive.mount('/content/drive/')\n",
    "    mount_drive()\n",
    "    print(\"Runnning on GOOGLE COLAB\")\n",
    "    isCloud = True\n",
    "except:\n",
    "    print(\"Runnning on LOCAL SYSTEM\")\n",
    "    isCloud = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4oPxUICKDj-"
   },
   "outputs": [],
   "source": [
    "class HAM_Data:\n",
    "    def __init__(self, images_path = \"data/HAM10000_images/\", data_info = \"data/HAM10000_metadata.csv\", split_files_path = \"data_files/\", resolution = (128, 128), toNormalize = True):\n",
    "        self.extra = '/content/drive/My Drive/' if isCloud else  \"\"\n",
    "        self.images_path = self.extra + images_path\n",
    "        self.total_data_info = pd.read_csv(self.extra + data_info)\n",
    "        images_labels = self.total_data_info[['image_id', 'dx']]\n",
    "        self.labels_dict = dict([(label, idx) for idx, label in enumerate(np.unique(images_labels['dx']))])\n",
    "        self.n_classes = len(self.labels_dict)\n",
    "        self.data_info = self.total_data_info.where(self.total_data_info['dx'] == 'nv').dropna()\n",
    "        self.operating_resolution = resolution\n",
    "        self.toNormalize = toNormalize\n",
    "        self.split_files_path = self.extra + split_files_path\n",
    "        self.get_training_info()\n",
    "        self.get_non_training_data()\n",
    "        \n",
    "    def get_training_info(self, isShuffle = True):\n",
    "        # change this according to data\n",
    "        images_labels = self.data_info[['image_id', 'dx']]\n",
    "        self.val_first = True\n",
    "        \n",
    "        if (self.split_files_path == self.extra + \"\") or (self.split_files_path == None):\n",
    "            self.data = list()\n",
    "            for idx, row in images_labels.iterrows():\n",
    "                self.data.append([row[0], row[-1]])\n",
    "            self.data = np.array(self.data)\n",
    "            if isShuffle: np.random.shuffle(self.data)\n",
    "            self.test_data = self.data[:int(len(self.data)*self.test_size)]\n",
    "            self.train_data = self.data[int(len(self.data)*self.test_size):]\n",
    "            self.val_data = self.train_data[:int(len(self.data)*self.val_size)]\n",
    "            self.train_data = self.train_data[int(len(self.data)*self.val_size):]\n",
    "\n",
    "            self.train_data = self.read_data(self.train_data)\n",
    "            print(\"Read train data to memory\")\n",
    "            self.test_data = self.read_data(self.test_data)\n",
    "            print(\"Read test data to memory\")\n",
    "            self.val_data = self.read_data(self.val_data)\n",
    "            print(\"Read validation data to memory\")\n",
    "            for type_, data_ in zip([\"train\", \"test\", \"val\"], [self.train_data, self.test_data, self.val_data]):\n",
    "                with open(os.path.join(self.save_path, type_ + \".pkl\"), \"wb\") as f:\n",
    "                    pkl.dump(data_, f)\n",
    "        else:\n",
    "            self.train_data = pkl.load(open(os.path.join(self.split_files_path, \"train.pkl\"), \"rb\"))\n",
    "            self.test_data = pkl.load(open(os.path.join(self.split_files_path, \"test.pkl\"), \"rb\"))\n",
    "            self.val_data = pkl.load(open(os.path.join(self.split_files_path, \"val.pkl\"), \"rb\"))\n",
    "    \n",
    "    def read_data(self, data):\n",
    "        return np.array([np.array([self.read_image(image_id), self.labels_dict[label]]) for image_id, label in data])\n",
    "\n",
    "    def path_from_id(self, image_id, images_path = None):\n",
    "        if images_path == None: images_path = self.images_path\n",
    "        if os.path.splitext(image_id)[-1] not in [\".jpg\", \".jpeg\", \".png\"]: image_id += \".jpg\"\n",
    "        return os.path.join(images_path, image_id)\n",
    "    \n",
    "    def read_image(self, image_id, images_path = None):\n",
    "        image = cv2.resize(cv2.imread(self.path_from_id(image_id, images_path)), self.operating_resolution)\n",
    "        if self.toNormalize: image = image.astype('float32') / 255.\n",
    "        return image\n",
    "                           \n",
    "    def train_batch_generator(self, images_only = False):\n",
    "        while True:\n",
    "            start = self.batch_read_count\n",
    "            end = (self.batch_read_count + self.batch_size) if (self.batch_read_count + self.batch_size) < len(self.train_data) else len(self.train_data)\n",
    "            X, y = np.array([i for i in self.train_data[start:end][:,0]]), np.array([i for i in self.train_data[start:end][:,1]])\n",
    "            self.batch_read_count += self.batch_size\n",
    "            if self.batch_read_count >= len(self.train_data): self.batch_read_count = 0\n",
    "            if not images_only: yield(X, y)\n",
    "            else: yield(X, X)\n",
    "            \n",
    "    def val_batch_generator(self, images_only = False):\n",
    "        while True:\n",
    "            if self.val_first:\n",
    "                np.random.shuffle(self.val_data)\n",
    "                self.val_X, self.val_y = np.array([i for i in self.val_data[:,0]]), np.array([i for i in self.val_data[:,1]])\n",
    "                self.val_first = False\n",
    "            if not images_only: yield(self.val_X, self.val_y)\n",
    "            else: yield(self.val_X, self.val_X)\n",
    "                \n",
    "    def get_non_training_data(self, n_samples = 100):\n",
    "        self.non_training_data_info = self.total_data_info.where(self.total_data_info['dx']!='nv').dropna()\n",
    "        # change this according to data\n",
    "        images_labels = self.non_training_data_info[['image_id', 'dx']]\n",
    "        shuffle(images_labels)\n",
    "        try:\n",
    "            self.nt_data = pkl.load(open(os.path.join(self.split_files_path, \"non_train.pkl\"), \"rb\"))\n",
    "        except:\n",
    "            self.nt_data = list()\n",
    "            for idx, row in images_labels.iterrows():\n",
    "                self.nt_data.append([row[0], row[-1]])\n",
    "                if idx == n_samples: break\n",
    "            self.nt_data = np.array(self.nt_data)\n",
    "\n",
    "            self.nt_data = self.read_data(self.nt_data)\n",
    "            print(\"Read non-train data to memory\")\n",
    "            with open(os.path.join(self.save_path, \"non_train.pkl\"), \"wb\") as f:\n",
    "                pkl.dump(self.nt_data, f)\n",
    "        return self.nt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPQUDCCsKDkP"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder:\n",
    "    def __init__(self, encoding_dim = 300 , resolution = (128,128)):\n",
    "        self.encoding_dimension = encoding_dim\n",
    "        self.input_shape = tuple(list(resolution) + [3])\n",
    "    \n",
    "    def get_model(self):\n",
    "        input_layer = Input(shape=(self.input_shape))\n",
    "        conv1 = Conv2D(16, (3,3), activation = 'relu', padding = 'same', name = \"conv1\")(input_layer)\n",
    "        mp1 = MaxPooling2D((2,2), padding = 'same', name = \"mp1\")(conv1)\n",
    "        conv2 = Conv2D(8, (3,3), activation = 'relu', padding = 'same', name = \"conv2\")(mp1)\n",
    "        mp2 = MaxPooling2D((2,2), padding = 'same', name = \"mp2\")(conv2)\n",
    "        conv3 = Conv2D(8, (3,3), activation = 'relu', padding = 'same', name = \"conv3\")(mp2)\n",
    "        encoding = MaxPooling2D((4,4), padding = 'same', name = \"encoding\")(conv3)\n",
    "\n",
    "        conv4 = Conv2D(8, (3, 3), activation='relu', padding='same', name = \"conv4\")(encoding)\n",
    "        up1 = UpSampling2D((4, 4), name = \"up1\")(conv4)\n",
    "        conv5 = Conv2D(8, (3, 3), activation='relu', padding='same', name = \"conv5\")(up1)\n",
    "        up2 = UpSampling2D((2, 2), name = \"up2\")(conv5)\n",
    "        conv6 = Conv2D(16, (3, 3), activation='relu', padding='same', name = \"conv6\")(up2)\n",
    "        up3 = UpSampling2D((2, 2), name = \"up3\")(conv6)\n",
    "        recons = Conv2D(3, (3, 3), activation='relu', padding='same', name = \"recons\")(up3)\n",
    "        return Model(input_layer, recons)\n",
    "\n",
    "class ContractiveAutoEncoder:\n",
    "    def __init__(self, encoding_dim = 300 , resolution = (128,128)):\n",
    "        self.encoding_dimension = encoding_dim\n",
    "        self.input_shape = tuple(list(resolution) + [3])\n",
    "    \n",
    "    def get_model(self):\n",
    "        input_layer = Input(shape=(self.input_shape))\n",
    "        conv1 = Conv2D(128, (3,3), padding = 'same', name = \"conv1\")(input_layer)\n",
    "        lr1 = LeakyReLU(name = 'lr1')(conv1)\n",
    "        mp1 = MaxPooling2D((4,4), padding = 'same', name = \"mp1\")(lr1)\n",
    "        \n",
    "        conv2 = Conv2D(512, (2,2), padding = 'same', name = \"conv2\")(mp1)\n",
    "        bn1 = BatchNormalization(name = 'bn1')(conv2)\n",
    "        lr2 = LeakyReLU(name = 'lr2')(bn1)\n",
    "        mp2 = MaxPooling2D((4,4), padding = 'same', name = \"mp2\")(lr2)\n",
    "        \n",
    "        conv3 = Conv2D(2048, (2,2), padding = 'same', name = \"conv3\")(mp2)\n",
    "        bn2 = BatchNormalization(name = 'bn2')(conv3)\n",
    "        lr3 = LeakyReLU(name = 'lr3')(bn2)\n",
    "        mp3 = MaxPooling2D((4,4), padding = 'same', name = \"mp3\")(lr3)\n",
    "        \n",
    "        encoding = Conv2D(300, (2,2), padding = 'same', name = 'encoding')(mp3)\n",
    "        \n",
    "        conv5 = Conv2D(2048, (2, 2), padding='same', name = \"conv5\")(encoding)\n",
    "        bn3 = BatchNormalization(name = 'bn3')(conv5)\n",
    "        lr4 = LeakyReLU(name = 'lr4')(bn3)\n",
    "        up1 = UpSampling2D((4, 4), name = \"up1\")(lr4)\n",
    "        \n",
    "        conv6 = Conv2D(512, (2, 2), padding='same', name = \"conv6\")(up1)\n",
    "        bn4 = BatchNormalization(name = 'bn4')(conv6)\n",
    "        lr5 = LeakyReLU(name = 'lr5')(bn4)\n",
    "        up2 = UpSampling2D((4, 4), name = \"up2\")(lr5)\n",
    "        \n",
    "        conv7 = Conv2D(128, (2, 2), padding='same', name = \"conv7\")(up2)\n",
    "        bn5 = BatchNormalization(name = 'bn5')(conv7)\n",
    "        lr6 = LeakyReLU(name = 'lr6')(bn5)\n",
    "        up3 = UpSampling2D((4, 4), name = \"up3\")(lr6)\n",
    "        \n",
    "        decoding = Conv2D(3, (2,2), padding = 'same', name = 'decoding')(up3)\n",
    "        \n",
    "        return Model(inputs = input_layer, outputs = decoding)\n",
    "    \n",
    "    def contractive_loss(self, y_pred, y_true, enc_layer_name = 'encoding', lam = 1e-3):\n",
    "        mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "\n",
    "        W = K.transpose(K.variable(value=model.get_layer(enc_layer_name).get_weights()[0])) # N_hidden x N\n",
    "        h = model.get_layer(enc_layer_name).output\n",
    "        dh = h * (1 - h)  # N_batch x N_hidden\n",
    "\n",
    "        # N_batch x N_hidden * N_hidden x 1 = N_batch x 1\n",
    "        contractive = lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "\n",
    "        return mse + contractive\n",
    "\n",
    "class ACNet:\n",
    "    def __init__(self, resolution = (128,128)):\n",
    "        self.input_shape = tuple(list(resolution) + [3])\n",
    "        \n",
    "    # ACNet\n",
    "    def convACB(self, input_layer, n_kernels, kernels_size, activation = 'relu', padding = 'same'):\n",
    "        out_dd = Conv2D(n_kernels, (kernels_size,kernels_size), activation = activation, padding = padding)(input_layer) # dxd\n",
    "        bn1 = BatchNormalization()(out_dd)\n",
    "        out_d1 = Conv2D(n_kernels, (kernels_size,1), activation = activation, padding = padding)(input_layer) # dx1\n",
    "        bn2 = BatchNormalization()(out_d1)\n",
    "        out_1d = Conv2D(n_kernels, (1,kernels_size), activation = activation, padding = padding)(input_layer) # 1xd\n",
    "        bn3 = BatchNormalization()(out_1d)\n",
    "        out_sum = Lambda(lambda a: a[0] + a[1] + a[2])([bn1, bn2, bn3])\n",
    "        return out_sum\n",
    "    \n",
    "    def get_model(self,):\n",
    "        input_layer = Input(shape=self.input_shape)\n",
    "        acb1 = convACB(input_layer, 16, 3)\n",
    "        mp1 = MaxPooling2D((2,2), padding = 'same', name = \"mp1\")(acb1)\n",
    "        acb2 = convACB(mp1, 8, 3)\n",
    "        mp2 = MaxPooling2D((2,2), padding = 'same', name = \"mp2\")(acb2)\n",
    "        acb3 = convACB(mp2, 8, 3)\n",
    "        encoding = MaxPooling2D((4,4), padding = 'same', name = \"encoding\")(acb3)\n",
    "\n",
    "        acb4 = convACB(encoding, 8, 3)\n",
    "        up1 = UpSampling2D((4, 4), name = \"up1\")(acb4)\n",
    "        acb5 = convACB(up1, 8, 3)\n",
    "        up2 = UpSampling2D((2, 2), name = \"up2\")(acb5)\n",
    "        acb6 = convACB(up2, 16, 3)\n",
    "        up3 = UpSampling2D((2, 2), name = \"up3\")(acb6)\n",
    "        recons = convACB(up3, 1, 3)\n",
    "        return Model(inputs = input_layer, outputs = recons)\n",
    "\n",
    "class ImageClassifier:\n",
    "    def __init__(self, n_classes, model_type = \"mobilenet\", resolution = (128,128)):\n",
    "        self.model_type = model_type\n",
    "        if \"mobilenet\" in self.model_type.lower():\n",
    "            self.model = MobileNetV2(input_shape = tuple(list(resolution) + [3]), weights = None, classes = n_classes)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMZ_KEGeKDkf"
   },
   "outputs": [],
   "source": [
    "class Trainer(HAM_Data):\n",
    "    def __init__(self, nn_type, save_path = \"output/\"):\n",
    "        self.nn_type = nn_type\n",
    "        extra = '/content/drive/My Drive/' if isCloud else  \"\"\n",
    "        self.save_path = extra + save_path\n",
    "        if not os.path.exists(self.save_path): os.mkdir(self.save_path)\n",
    "        self.train_config()\n",
    "        HAM_Data.__init__(self)\n",
    "        self.determine_model()\n",
    "    \n",
    "    def determine_model(self):\n",
    "        if \"autoencoder\" in self.nn_type.lower():\n",
    "            self.ae = AutoEncoder(resolution = self.operating_resolution)\n",
    "            self.model = self.ae.get_model()\n",
    "            self.train = self.train_autoencoder\n",
    "        elif \"contractive_autoencoder\" in self.nn_type.lower():\n",
    "            self.cae = ContractiveAutoEncoder()\n",
    "            self.model = self.cae.get_model()\n",
    "            self.train = self.train_contractive_autoencoder\n",
    "        elif \"classifier\" in self.nn_type.lower():\n",
    "            self.ic = ImageClassifier(n_classes = self.n_classes, model_type = \"mobilenet\", resolution = self.operating_resolution)\n",
    "            self.model = self.ic.get_model()\n",
    "            self.train = self.train_classifier\n",
    "        elif \"ACNet\" in self.nn_type.lower():\n",
    "            self.acn_ae = ACNet()\n",
    "            self.model = self.acn_ae.get_model()\n",
    "            self.train = self.train_ACNet_autoencoder\n",
    "    \n",
    "    def train_config(self, model_name = \"\"):\n",
    "        self.batch_size = 64\n",
    "        self.mini_batch_size = 16\n",
    "        self.epochs = 70\n",
    "        self.test_size = 0.015\n",
    "        self.val_size = 0.01\n",
    "        \n",
    "        self.operating_resolution = (128,128)\n",
    "        self.batch_read_count = 0\n",
    "        \n",
    "        self.model_name = os.path.join(self.save_path, self.nn_type + \"-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n",
    "        self.callback = [ModelCheckpoint(self.model_name, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')]\n",
    "\n",
    "        self.adam = Adam(learning_rate = 1e-4)\n",
    "\n",
    "    \n",
    "    def train_classifier(self):\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer=self.adam, metrics=['accuracy'])        \n",
    "        self.model.fit_generator(self.train_batch_generator(), validation_data = self.val_batch_generator(), epochs = self.epochs, steps_per_epoch = int(len(self.train_data) / self.batch_size), shuffle = True, validation_steps = 1, callbacks = callback)\n",
    "    \n",
    "    def train_autoencoder(self):\n",
    "        self.model.compile(loss = 'mse', optimizer = self.adam, metrics = ['accuracy'])\n",
    "        self.model.fit_generator(self.train_batch_generator(True), validation_data = self.val_batch_generator(True), epochs = self.epochs, steps_per_epoch = int(len(self.train_data) / self.batch_size), shuffle = True, validation_steps = 1, callbacks = self.callback)\n",
    "        \n",
    "    def train_contractive_autoencoder(self):\n",
    "        contractive_loss = self.cae.contractive_loss\n",
    "        self.model.compile(loss = 'contractive_loss', optimizer = self.adam, metrics = ['accuracy'])\n",
    "        self.model.fit_generator(self.train_batch_generator(True), validation_data = self.val_batch_generator(True), epochs = self.epochs, steps_per_epoch = int(len(self.train_data) / self.batch_size), shuffle = True, validation_steps = 1, callbacks = self.callback)\n",
    "    \n",
    "    def train_ACNet_autoencoder(self):\n",
    "        self.model.compile(loss = 'mse', optimizer = self.adam, metrics = ['accuracy'])\n",
    "        self.model.fit_generator(self.train_batch_generator(True), validation_data = self.val_batch_generator(True), epochs = self.epochs, steps_per_epoch = int(len(self.train_data) / self.batch_size), shuffle = True, validation_steps = 1, callbacks = self.callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_CIK6CbQHVB"
   },
   "outputs": [],
   "source": [
    "class Tester(HAM_Data):\n",
    "    def __init__(self, model_path = \"models/autoencoder_512-49-0.95.hdf5\", save_path = \"output/\"):\n",
    "        extra = '/content/drive/My Drive/' if isCloud else  \"\"\n",
    "        self.save_path = extra + save_path\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.model = load_model(self.model_path)\n",
    "        HAM_Data.__init__(self)\n",
    "        if \"autoencoder\" in self.model_path:\n",
    "            self.test = self.test_autoencoder\n",
    "        elif \"classifier\" in self.model_path:\n",
    "            self.test = self.test_classifier\n",
    "    \n",
    "    def display_AE_result(self, original_image, reconstructed_image):\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(original_image)\n",
    "        ax[1].imshow(reconstructed_image)\n",
    "        plt.show()         \n",
    "    \n",
    "    def test_autoencoder(self, images, read_images = True, show_result = True):\n",
    "        if not isinstance(images, np.ndarray): images = np.array(images)\n",
    "        mse_results = list()\n",
    "        reconstruction_results = list()\n",
    "        for image in images:\n",
    "            original_image = self.read_image(image) if read_images else image\n",
    "            reconstructed_image = np.squeeze(self.model.predict(np.expand_dims(original_image, axis = 0)))\n",
    "            mse_ = mse(original_image.flatten(), reconstructed_image.flatten())\n",
    "            if show_result: self.display_AE_result(original_image, reconstructed_image); print(\"MSE:\", mse_)\n",
    "            mse_results.append(mse_)\n",
    "            reconstruction_results.append(reconstructed_image)\n",
    "        return np.array(mse_results), np.array(reconstruction_results)\n",
    "    \n",
    "    def test_roc_score(self):\n",
    "        anomalous_data = self.get_non_training_data()\n",
    "        non_anomalous_images = self.test_data[:, 0]\n",
    "        non_anomalous_labels = np.zeros(len(non_anomalous_images))\n",
    "        anomalous_images = anomalous_data[:, 0]\n",
    "        anomalous_labels = np.ones(len(anomalous_images))\n",
    "        test_images = np.hstack((non_anomalous_images, anomalous_images))\n",
    "        test_labels = np.hstack((non_anomalous_labels, anomalous_labels))\n",
    "        mse_results, reconstruction_results = self.test(test_images, read_images = False, show_result = False)\n",
    "        AUCROC_score = roc_auc_score(test_labels, mse_results)\n",
    "        print(\"ROC AUC Score:\", AUCROC_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3G3uYhr3KDkz",
    "outputId": "56226d02-bf9d-498e-a681-4b3f910dccf6"
   },
   "outputs": [],
   "source": [
    "acn_ae_tr = Trainer(nn_type = \"ACNet\", save_path = \"ACN_AE_12042020\")\n",
    "acn_ae_tr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "P8QMx1DRHs56",
    "outputId": "7a0ba28c-5898-46b4-d712-db60f62564e0"
   },
   "outputs": [],
   "source": [
    "# cae_tr = Trainer(nn_type = \"contractive_autoencoder\", save_path = \"CAE_05042020\")\n",
    "# cae_tr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pvJANrSaQHVw",
    "outputId": "6e0b015e-8450-4798-ddf0-14c74b28c8fe"
   },
   "outputs": [],
   "source": [
    "# # Testing De-Noising AutoEncoder\n",
    "# ts = Tester(model_path = \"/content/drive/My Drive/AE_05042020/autoencoder-70-0.94.hdf5\", save_path = \"data_files/\")\n",
    "# ts.test_roc_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EnBW655qQHWK",
    "outputId": "2742ec92-c980-4cea-c695-9f33c8106dd2"
   },
   "outputs": [],
   "source": [
    "# # Testing Contractive AutoEncoder\n",
    "# ts = Tester(model_path = \"/content/drive/My Drive/CAE_05042020/contractive_autoencoder-70-0.95.hdf5\", save_path = \"data_files/\")\n",
    "# ts.test_roc_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZJ-UlREj18h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_ACNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 128, 128, 16) 160         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 128, 128, 16) 64          input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 128, 128, 16) 64          input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 128, 128, 16) 0           conv2d_325[0][0]                 \n",
      "                                                                 conv2d_326[0][0]                 \n",
      "                                                                 conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mp1 (MaxPooling2D)              (None, 64, 64, 16)   0           lambda_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 64, 64, 8)    1160        mp1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 64, 64, 8)    392         mp1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 64, 64, 8)    392         mp1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 64, 64, 8)    0           conv2d_328[0][0]                 \n",
      "                                                                 conv2d_329[0][0]                 \n",
      "                                                                 conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mp2 (MaxPooling2D)              (None, 32, 32, 8)    0           lambda_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 32, 32, 8)    584         mp2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 32, 32, 8)    200         mp2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 32, 32, 8)    200         mp2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 32, 32, 8)    0           conv2d_331[0][0]                 \n",
      "                                                                 conv2d_332[0][0]                 \n",
      "                                                                 conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoding (MaxPooling2D)         (None, 8, 8, 8)      0           lambda_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 8, 8, 8)      584         encoding[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 8, 8, 8)      200         encoding[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 8, 8, 8)      200         encoding[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 8, 8, 8)      0           conv2d_334[0][0]                 \n",
      "                                                                 conv2d_335[0][0]                 \n",
      "                                                                 conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up1 (UpSampling2D)              (None, 32, 32, 8)    0           lambda_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 32, 32, 8)    584         up1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 32, 32, 8)    200         up1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 32, 32, 8)    200         up1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None, 32, 32, 8)    0           conv2d_337[0][0]                 \n",
      "                                                                 conv2d_338[0][0]                 \n",
      "                                                                 conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up2 (UpSampling2D)              (None, 64, 64, 8)    0           lambda_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 64, 64, 16)   1168        up2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 64, 64, 16)   400         up2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 64, 64, 16)   400         up2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, 64, 64, 16)   0           conv2d_340[0][0]                 \n",
      "                                                                 conv2d_341[0][0]                 \n",
      "                                                                 conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up3 (UpSampling2D)              (None, 128, 128, 16) 0           lambda_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 128, 128, 1)  145         up3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 128, 128, 1)  49          up3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 128, 128, 1)  49          up3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, 128, 128, 1)  0           conv2d_343[0][0]                 \n",
      "                                                                 conv2d_344[0][0]                 \n",
      "                                                                 conv2d_345[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,395\n",
      "Trainable params: 7,395\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AnomalyDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
