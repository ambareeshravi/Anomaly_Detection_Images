{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEq40taKKDjG"
   },
   "outputs": [],
   "source": [
    "import cv2, numpy as np, pandas as pd, os, shutil, pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "We9Nol9XKDjo",
    "outputId": "4b44ab77-2920-4764-acac-84e2a4400662"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "try: from keras.callbacks.callbacks import ModelCheckpoint\n",
    "except:  from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "mIzfydx1KGzn",
    "outputId": "aa1180ab-6595-410c-8a6b-91fe74d883d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnning on LOCAL SYSTEM\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # to run on colab\n",
    "    from google.colab import drive\n",
    "    def mount_drive():\n",
    "        drive.mount('/content/drive/')\n",
    "    mount_drive()\n",
    "    print(\"Runnning on GOOGLE COLAB\")\n",
    "    isCloud = True\n",
    "except:\n",
    "    print(\"Runnning on LOCAL SYSTEM\")\n",
    "    isCloud = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4oPxUICKDj-"
   },
   "outputs": [],
   "source": [
    "class HAM_Data:\n",
    "    def __init__(self, images_path = \"data/HAM10000_images/\", data_info = \"data/HAM10000_metadata.csv\", resolution = (128, 128), toNormalize = True):\n",
    "        extra = '/content/drive/My Drive/' if isCloud else  \"\"\n",
    "        self.images_path = extra + images_path\n",
    "        self.data_info = pd.read_csv(extra + data_info)\n",
    "        self.operating_resolution = resolution\n",
    "        self.toNormalize = toNormalize\n",
    "        self.get_training_info()\n",
    "        \n",
    "    def get_training_info(self, isShuffle = True):\n",
    "        # change this according to data\n",
    "        images_labels = self.data_info[['image_id', 'dx']]\n",
    "        self.labels_dict = dict([(label, idx) for idx, label in enumerate(np.unique(images_labels['dx']))])\n",
    "        self.n_classes = len(self.labels_dict)\n",
    "        self.val_first = True\n",
    "        self.data = list()\n",
    "        for idx, row in images_labels.iterrows():\n",
    "            self.data.append([row[0], row[-1]])\n",
    "        self.data = np.array(self.data)\n",
    "        if isShuffle: np.random.shuffle(self.data)\n",
    "        self.test_data = self.data[:int(len(self.data)*self.test_size)]\n",
    "        self.train_data = self.data[int(len(self.data)*self.test_size):]\n",
    "        self.val_data = self.train_data[:int(len(self.data)*self.val_size)]\n",
    "        self.train_data = self.train_data[int(len(self.data)*self.val_size):]\n",
    "        \n",
    "        self.train_data = self.read_data(self.train_data)\n",
    "        print(\"Read train data to memory\")\n",
    "        self.test_data = self.read_data(self.test_data)\n",
    "        print(\"Read test data to memory\")\n",
    "        self.val_data = self.read_data(self.val_data)\n",
    "        print(\"Read validation data to memory\")\n",
    "        for type_, data_ in zip([\"train\", \"test\", \"val\"], [self.train_data, self.test_data, self.val_data]):\n",
    "            with open(os.path.join(self.save_path, type_ + \".pkl\"), \"wb\") as f:\n",
    "                pkl.dump(data_, f)\n",
    "    \n",
    "    def read_data(self, data):\n",
    "        return np.array([np.array([self.read_image(image_id), self.labels_dict[label]]) for image_id, label in data])\n",
    "\n",
    "    def path_from_id(self, image_id):\n",
    "        return os.path.join(self.images_path, image_id + \".jpg\")\n",
    "    \n",
    "    def read_image(self, image_id):\n",
    "        image = cv2.resize(cv2.imread(self.path_from_id(image_id)), self.operating_resolution)\n",
    "        if self.toNormalize: image = image.astype('float32') / 255.\n",
    "        return image\n",
    "                           \n",
    "    def train_batch_generator(self, images_only = False):\n",
    "        while True:\n",
    "            start = self.batch_read_count\n",
    "            end = (self.batch_read_count + self.batch_size) if (self.batch_read_count + self.batch_size) < len(self.train_data) else len(self.train_data)\n",
    "            X, y = np.array([i for i in self.train_data[start:end][:,0]]), np.array([i for i in self.train_data[start:end][:,1]])\n",
    "            self.batch_read_count += self.batch_size\n",
    "            if self.batch_read_count >= len(self.train_data): self.batch_read_count = 0\n",
    "            if not images_only: yield(X, y)\n",
    "            else: yield(X, X)\n",
    "            \n",
    "    def val_batch_generator(self, images_only = False):\n",
    "        while True:\n",
    "            if self.val_first:\n",
    "                np.random.shuffle(self.val_data)\n",
    "                self.val_X, self.val_y = np.array([i for i in self.val_data[:,0]]), np.array([i for i in self.val_data[:,1]])\n",
    "                self.val_first = False\n",
    "            if not images_only: yield(self.val_X, self.val_y)\n",
    "            else: yield(self.val_X, self.val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPQUDCCsKDkP"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder:\n",
    "    def __init__(self, encoding_dim = 300 , resolution = (128,128)):\n",
    "        self.encoding_dimension = encoding_dim\n",
    "        self.input_shape = tuple(list(resolution) + [3])\n",
    "    \n",
    "    def get_model(self):\n",
    "        input_layer = Input(shape=(self.input_shape))\n",
    "        conv1 = Conv2D(16, (3,3), activation = 'relu', padding = 'same')(input_layer)\n",
    "        mp1 = MaxPooling2D((2,2), padding = 'same')(conv1)\n",
    "        conv2 = Conv2D(8, (3,3), activation = 'relu', padding = 'same')(mp1)\n",
    "        mp2 = MaxPooling2D((2,2), padding = 'same')(conv2)\n",
    "        conv3 = Conv2D(8, (3,3), activation = 'relu', padding = 'same')(mp2)\n",
    "        encoding = MaxPooling2D((2,2), padding = 'same')(conv3)\n",
    "\n",
    "        conv4 = Conv2D(8, (3, 3), activation='relu', padding='same')(encoding)\n",
    "        up1 = UpSampling2D((2, 2))(conv4)\n",
    "        conv5 = Conv2D(8, (3, 3), activation='relu', padding='same')(up1)\n",
    "        up2 = UpSampling2D((2, 2))(conv5)\n",
    "        conv6 = Conv2D(16, (3, 3), activation='relu', padding='same')(up2)\n",
    "        up3 = UpSampling2D((2, 2))(conv6)\n",
    "        recons = Conv2D(3, (3, 3), activation='relu', padding='same')(up3)\n",
    "        return Model(input_layer, recons)\n",
    "\n",
    "class ImageClassifier:\n",
    "    def __init__(self, n_classes, model_type = \"mobilenet\", resolution = (128,128)):\n",
    "        self.model_type = model_type\n",
    "        if \"mobilenet\" in self.model_type.lower():\n",
    "            self.model = MobileNetV2(input_shape = tuple(list(resolution) + [3]), weights = None, classes = n_classes)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMZ_KEGeKDkf"
   },
   "outputs": [],
   "source": [
    "class Trainer(HAM_Data):\n",
    "    def __init__(self, nn_type, save_path = \"output/\"):\n",
    "        self.nn_type = nn_type\n",
    "        extra = '/content/drive/My Drive/' if isCloud else  \"\"\n",
    "        self.save_path = extra + save_path\n",
    "        if os.path.exists(self.save_path): shutil.rmtree(self.save_path)\n",
    "        os.mkdir(self.save_path)\n",
    "        self.train_config()\n",
    "        HAM_Data.__init__(self)\n",
    "        self.determine_model()\n",
    "    \n",
    "    def determine_model(self):\n",
    "        if \"autoencoder\" in self.nn_type.lower():\n",
    "            self.ae = AutoEncoder(resolution = self.operating_resolution)\n",
    "            self.model = self.ae.get_model()\n",
    "            self.train = self.train_autoencoder\n",
    "        elif \"classifier\" in self.nn_type.lower():\n",
    "            self.ic = ImageClassifier(n_classes = self.n_classes, model_type = \"mobilenet\", resolution = self.operating_resolution)\n",
    "            self.model = self.ic.get_model()\n",
    "            self.train = self.train_classifier\n",
    "    \n",
    "    def train_config(self, model_name = \"\"):\n",
    "        self.batch_size = 32\n",
    "        self.mini_batch_size = 16\n",
    "        self.epochs = 50\n",
    "        self.test_size = 0.2\n",
    "        self.val_size = 0.1\n",
    "        \n",
    "        self.operating_resolution = (128,128)\n",
    "        self.batch_read_count = 0\n",
    "        \n",
    "        self.model_name = os.path.join(self.save_path, self.nn_type + \"-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n",
    "        self.callback = [ModelCheckpoint(self.model_name, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')]\n",
    "    \n",
    "    def train_classifier(self):\n",
    "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])        \n",
    "        self.model.fit_generator(self.train_batch_generator(), validation_data = self.val_batch_generator(), epochs = self.epochs, steps_per_epoch = int(len(self.train_data) / self.batch_size), shuffle = True, validation_steps = 1, callbacks = callback)\n",
    "    \n",
    "    def train_autoencoder(self):\n",
    "        self.model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "        self.model.fit_generator(self.train_batch_generator(True), validation_data = self.val_batch_generator(True), epochs = self.epochs, steps_per_epoch = int(len(self.train_data) / self.batch_size), shuffle = True, validation_steps = 1, callbacks = self.callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "3G3uYhr3KDkz",
    "outputId": "94760910-ee59-4a63-a9ca-445c816bc142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train data to memory\n",
      "Read test data to memory\n",
      "Read validation data to memory\n"
     ]
    }
   ],
   "source": [
    "t = Trainer(nn_type = \"autoencoder\", save_path = \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/autoencoder-{epoch:02d}-{val_accuracy:.2f}.hdf5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "tfHIa-RiKDlD",
    "outputId": "f6999362-7991-4889-b933-f6e98cc52e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.3725 - accuracy: 0.5243 - val_loss: 0.3559 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80874, saving model to output/autoencoder-01-0.81.hdf5\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 2s 487ms/step - loss: 0.3378 - accuracy: 0.7922 - val_loss: 0.2965 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.80874 to 0.83810, saving model to output/autoencoder-02-0.84.hdf5\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 2s 497ms/step - loss: 0.2756 - accuracy: 0.7895 - val_loss: 0.2304 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.83810 to 0.84641, saving model to output/autoencoder-03-0.85.hdf5\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 2s 473ms/step - loss: 0.2450 - accuracy: 0.8228 - val_loss: 0.2264 - val_accuracy: 0.8465\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84641 to 0.84648, saving model to output/autoencoder-04-0.85.hdf5\n",
      "Epoch 5/50\n",
      "2/4 [==============>...............] - ETA: 1s - loss: 0.2112 - accuracy: 0.8289"
     ]
    }
   ],
   "source": [
    "t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AnomalyDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
